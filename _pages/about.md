---
permalink: /
title: "Kevin Bai - Data Analyst/Data Scientist"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

<div class="page-intro">
A analytics professional with 4 years of experience using machine learning, statistical modeling, and big data tools to solve complex problems and deliver actionable insights. Proficient in Python, R, SQL, and cloud platforms, I have developed predictive models that improved operational efficiency and decision-making across industries. My ability to translate technical findings into business strategies makes me a strong candidate for roles focused on innovation and impact.
</div>

## Projects
**[Twitter Sentiment Analysis](https://github.com/kbai612)**
- Designed and implemented a sentiment analysis pipeline leveraging the Twitter API to collect real-time tweets, applied advanced natural language processing (NLP) techniques (tokenization, stop-word removal, TF-IDF vectorization), and trained a Bidirectional LSTM model to classify sentiments as positive, negative, or neutral with 85% accuracy.
- Developed a real-time analytics system using Apache Kafka for streaming tweet data, Spark for batch processing and sentiment scoring, and PostgreSQL for storing sentiment trends, enabling dynamic monitoring of public opinion during live events.
- Created an interactive dashboard using Flask and Plotly to visualize sentiment trends over time, geographic distributions of sentiments, and keyword-based insights, providing actionable intelligence for marketing and policy decision-making.
- Optimized data preprocessing workflows, reducing noise in text data by implementing custom regex patterns for hashtag and emoji handling, achieving a 10% improvement in model performance metrics such as precision and recall.

**[Local RAG AI Agent for Sensitive Documentation](https://github.com/kbai612)**
- Architected a fully local AI infrastructure integrating Ollama (LLMs), Qdrant (vector database), PostgreSQL (SQL database), and n8n (workflow automation) using Docker Compose, ensuring complete data privacy and control.
- Developed a Retrieval-Augmented Generation (RAG) AI agent, enabling efficient document retrieval and context-aware interactions by combining vector search with LLMs and structured memory storage.
- Streamlined document ingestion workflows by automating text extraction from Google Drive, vectorizing content, and storing metadata in Qdrant, significantly enhancing data processing efficiency.
- Built scalable, no-code workflows in n8n, facilitating seamless integration of AI tools while supporting custom configurations for advanced use cases like embedding models and caching mechanisms.

## Work Experience
**Technical Data Analyst @ StackAdapt (_August 2023 - Present_)**
-	Leveraged historical data and advanced analytics techniques to optimize political advertising strategies for the 2024 US election cycle, resulting in a 156.3% increase in CTV/Video ad spending compared to the 2020 election cycle.
-	Developed a KPI monitoring system which utilized ThoughtSpot dashboards, email alerts and slack alerts to detect short term anomalies and monitor long term trends, leading to 95% of health breaches being caught on the day that it happened.
-	Conducted A/B testing to validate an initial click-through rate hypothesis, adjusting frequency caps for different audience   segments which improved overall campaign efficiency and resulted in a 25% increase in spend and click KPIs.
-	Developed and implemented an automated data pipeline using SQL, Python and Snowflake, enabling real-time campaign reporting, optimization, and analysis. This solution resulted in a 45% reduction in time spent creating reports and allowing for a 35% increase in ad spend efficiency by identifying and utilizing optimal ad inventory for campaigns.
-	Utilized decision trees and feature engineering to determine fraudulent ad probabilities on an impression level, allowing for faster detection and blocks for fraudulent domain inventory, reducing false positives by 30% and increasing fraud detection accuracy by 80%.

**Business Intelligence Analyst @ Brokerlink (_December 2021 - May 2023_)**
-	Collaborated with Revenue and Leadership teams to implement a data-driven underwriting strategy, leveraging advanced analytics to reduce the average claim value by 12% and improve the loss ratio by 5% over 3 fiscal quarters.
-	Designed and implemented scalable data pipelines on AWS using Glue, Lambda, and S3, integrating with MariaDB for efficient data management, resulting in a 50% reduction in data processing time and saving the team approximately 20 hours per week on data-related tasks 
-	Spearheaded a data visualization project using Power BI for the commercial lines department, creating interactive dashboards to monitor KPIs, line health, and action items, resulting in a 15% improvement in data-driven decision-making and a 10% reduction in response time to critical alerts. 
-	Developed retention analysis using XG boost method applied in python for binary classification model and outputs with identification of clients with most likelihood of cancellation for stakeholder teams to proactively re-market, leading to an increased in commercial lines account retention by 40% from Q4 to Q1

**Data Analyst @ Nova Century Scientific Inc (_August 2020 - January 2021_)**
-	Developed and deployed a robust relational data warehouse solution utilizing SQL Server, integrating key metrics such as customer demographics, sales performance, and inventory levels, resulting in a 70% reduction in report generation time and a 12% improvement in data accuracy.
-	Collaborated with the leadership team to design and implement Power BI dashboards that facilitated real-time data analysis, resulting in a 32% increase in the identification of key data trends and a 25% improvement in tracking and monitoring key performance indicators (KPIs).
-	Leveraged VBA programming to enhance analysis formatting, report generation, data lookups, and interface functionality, resulting in a 50% improvement in data retrieval efficiency
-	Designed and maintained monthly performance reports that helped identify key trends and led to a 15% reduction in operational costs over six months.


## Education
**Georgia Institute of Technology** | M.S. Computational Analytics (Data Science)  
Regression Analysis, Bayesian Statistics, Time Series Forecasting, Simulation, Deep Learning, Data Visualization, MLOps, Graduate Level Algorithmns

**University of Waterloo** | B.A. Accounting and Financial Management  
Statistical Analysis, Business Strategy, Equity Investments, Quantitative Finance, Stochastic Processes and Applications, Multivariable Calculus